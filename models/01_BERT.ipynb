{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conda env: `aops_tenflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IBDA\\.conda\\envs\\victor_aops_tenflow\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\IBDA\\.conda\\envs\\victor_aops_tenflow\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "from time import perf_counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.utils_for_classification import classification_evaluation\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 16\n",
    "\n",
    "epochs = 8\n",
    "learning_rate = 1e-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2524 files belonging to 4 classes.\n",
      "Found 703 files belonging to 4 classes.\n",
      "Found 283 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds_ = tf.keras.utils.text_dataset_from_directory('../data/classification/train', batch_size=batch_size)\n",
    "train_ds = train_ds_.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_ds = tf.keras.utils.text_dataset_from_directory('../data/classification/test', batch_size=batch_size)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory('../data/classification/val', batch_size=batch_size)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "class_names = train_ds_.class_names\n",
    "\n",
    "# Map string labels to integer indices\n",
    "label_processor = tf.keras.layers.StringLookup(\n",
    "    vocabulary=['Algebra', 'Combinatorics', 'Geometry', 'Number Theory'],\n",
    "    mask_token=None  # Treats unknown tokens as missing values\n",
    ")\n",
    "\n",
    "train_labels = train_ds.map(lambda text, label: label_processor(label))\n",
    "test_labels = test_ds.map(lambda text, label: label_processor(label))\n",
    "val_labels = val_ds.map(lambda text, label: label_processor(label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModel:\n",
    "    def __init__(self, tfhub_preprocess, tfhub_encoder, seq_length=512):\n",
    "        self.tfhub_preprocess = tfhub_preprocess\n",
    "        self.tfhub_encoder = tfhub_encoder\n",
    "        self.seq_length = seq_length\n",
    "        self.model = self.__build_model()\n",
    "        self.history = None\n",
    "        \n",
    "        self.train_ds = None\n",
    "        self.validation_data = None\n",
    "        self.epochs = None\n",
    "        self.learning_rate = None\n",
    "        self.optimizer_type = None\n",
    "        self.loss = None\n",
    "        self.metrics = None\n",
    "        self.optimizer = None\n",
    "        self.__is_compiled = False\n",
    "        \n",
    "        self.__is_trained = False\n",
    "\n",
    "        self.training_time = None\n",
    "\n",
    "    def __build_model(self):\n",
    "        # Step 1: Define text input layer\n",
    "        text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "        \n",
    "        # Step 2: Tokenize batches of text inputs\n",
    "        bert_preprocess = hub.load(self.tfhub_preprocess)\n",
    "        tokenize = hub.KerasLayer(bert_preprocess.tokenize)\n",
    "        tokenized_input = tokenize(text_input)\n",
    "        \n",
    "        # Step 3: Pack input sequences for the Transformer encoder\n",
    "        bert_pack_inputs = hub.KerasLayer(\n",
    "            bert_preprocess.bert_pack_inputs,\n",
    "            arguments=dict(seq_length=self.seq_length))\n",
    "        encoder_inputs = bert_pack_inputs([tokenized_input])\n",
    "        \n",
    "        # Load BERT encoder\n",
    "        encoder = hub.KerasLayer(self.tfhub_encoder, trainable=True, name='BERT_encoder')\n",
    "        # Pass encoder inputs through BERT encoder\n",
    "        outputs = encoder(encoder_inputs)\n",
    "\n",
    "        # Define classifier layers\n",
    "        net = outputs['pooled_output']\n",
    "        net = tf.keras.layers.Dropout(0.1)(net)\n",
    "        net = tf.keras.layers.Dense(512, activation='relu')(net)  # Additional dense layer\n",
    "        net = tf.keras.layers.Dropout(0.1)(net)\n",
    "        net = tf.keras.layers.Dense(256, activation='relu')(net)  # Additional dense layer\n",
    "        net = tf.keras.layers.Dropout(0.1)(net)\n",
    "        net = tf.keras.layers.Dense(128, activation='relu')(net)  # Additional dense layer\n",
    "        net = tf.keras.layers.Dropout(0.1)(net)\n",
    "        net = tf.keras.layers.Dense(4, activation='softmax', name='classifier')(net)\n",
    "        \n",
    "        return tf.keras.Model(text_input, net)\n",
    "    \n",
    "    def compile_model(\n",
    "        self, \n",
    "        train_ds, \n",
    "        validation_data,\n",
    "        epochs, \n",
    "        learning_rate, \n",
    "        optimizer_type='adamw', \n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,   # Assuming you have integer labels\n",
    "        metrics=['accuracy']):\n",
    "        \n",
    "        self.train_ds = train_ds\n",
    "        self.validation_data = validation_data\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer_type = optimizer_type\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        \n",
    "        steps_per_epoch = tf.data.experimental.cardinality(self.train_ds).numpy()\n",
    "        num_train_steps = steps_per_epoch * self.epochs\n",
    "        optimizer = optimization.create_optimizer(\n",
    "            init_lr=self.learning_rate,\n",
    "            num_train_steps=num_train_steps,\n",
    "            num_warmup_steps=int(0.1*num_train_steps),\n",
    "            optimizer_type=self.optimizer_type\n",
    "        )\n",
    "        self.optimizer= optimizer\n",
    "        \n",
    "        # Comple model\n",
    "        self.model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics)\n",
    "        self.__is_compiled = True\n",
    "    \n",
    "    def train(self):\n",
    "        if self.__is_compiled is False: raise Warning(\"Model is not compiled yet\")\n",
    "        \n",
    "        print(f\"Model       : {self.tfhub_encoder}\")\n",
    "        print(f\"Preprocessor: {self.tfhub_preprocess}\\n\")\n",
    "\n",
    "        print(f\"epochs       : {self.epochs}\")\n",
    "        print(f\"learning_rate: {self.learning_rate}\\n\")\n",
    "\n",
    "        start = perf_counter()\n",
    "        history = self.model.fit(\n",
    "            self.train_ds, \n",
    "            validation_data=self.validation_data, \n",
    "            epochs=self.epochs\n",
    "            )\n",
    "        end = perf_counter()\n",
    "        print(f\"\\nTotal training time: {end-start:.2f}s\")\n",
    "        \n",
    "        self.training_time = end-start\n",
    "        self.history = history.history\n",
    "        self.__is_trained = True\n",
    "        return history\n",
    "    \n",
    "    def evaluate_test(self, test_ds):\n",
    "        if self.__is_trained is False: raise Warning(\"Model is not trained yet\")\n",
    "\n",
    "        self.model.evaluate(test_ds)\n",
    "\n",
    "        X_test, y_actual_string, y_actual_mapped = [], [], []\n",
    "        for text_, label_ in test_ds:\n",
    "            text_, label_ = list(text_.numpy()), list(label_.numpy())\n",
    "            y_actual_mapped += label_\n",
    "            for i, item in enumerate(label_):\n",
    "                if item == 0:\n",
    "                    label_[i] = class_names[0]\n",
    "                elif item == 1:\n",
    "                    label_[i] = class_names[1]\n",
    "                elif item == 2:\n",
    "                    label_[i] = class_names[2]\n",
    "                elif item == 3:\n",
    "                    label_[i] = class_names[3]\n",
    "                else: raise ValueError(\"Tidak mungkin error!\")\n",
    "            X_test += text_\n",
    "            y_actual_string += label_\n",
    "\n",
    "        y_actual_mapped = tf.constant(y_actual_mapped)\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_listed = list(y_pred)\n",
    "        for i, item in enumerate(y_pred_listed):\n",
    "            temp = list(item)\n",
    "            if temp.index(max(temp)) == 0: y_pred_listed[i] = class_names[0]\n",
    "            elif temp.index(max(temp)) == 1: y_pred_listed[i] = class_names[1]\n",
    "            elif temp.index(max(temp)) == 2: y_pred_listed[i] = class_names[2]\n",
    "            elif temp.index(max(temp)) == 3: y_pred_listed[i] = class_names[3]\n",
    "            else: raise ValueError(\"Never error!\")\n",
    "\n",
    "        print()\n",
    "        heatmap, report = classification_evaluation(y_actual_string, y_pred_listed)\n",
    "        loss_test = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_actual_mapped, y_pred))\n",
    "        print(f\"loss: {loss_test}\")\n",
    "        heatmap.plot()\n",
    "        plt.show()\n",
    "        \n",
    "        return report, loss_test, heatmap\n",
    "\n",
    "    def plot_training_history_over_time(self, figsize=(14, 4)):\n",
    "        if self.history is None: raise Warning(\"Nothing to plot because model is not trained yet\")\n",
    "        \n",
    "        print(self.history.keys())\n",
    "        print(\"Training history over time\")\n",
    "        \n",
    "        acc = self.history['accuracy']\n",
    "        val_acc = self.history['val_accuracy']\n",
    "        loss = self.history['loss']\n",
    "        val_loss = self.history['val_loss']\n",
    "        epochs = range(1, len(acc) + 1)\n",
    "        \n",
    "        figure, ax = plt.subplots(1, 2, figsize=figsize, layout=\"constrained\")\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, loss, 'r', label='Training loss')  # r is for \"solid red line\"\n",
    "        plt.plot(epochs, val_loss, 'b', label='Validation loss')  # b is for \"solid blue line\"\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "        plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "\n",
    "    def predict(self, text: list):\n",
    "        \"\"\"\n",
    "            text: should parsed like this --> [\"Your text here!\"]\n",
    "        \"\"\"\n",
    "        return self.model.predict(tf.constant(text))\n",
    "\n",
    "optimizer_type = 'adamw'\n",
    "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
    "metrics = ['accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfhub_map = {\n",
    "    \"BERT-EN-CASED-L-12-H-768-A-12\" : \"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-cased-l-12-h-768-a-12/versions/4\",\n",
    "    \"BERT-EN-UNCASED-L-2-H-512-A-8\": \"https://www.kaggle.com/models/tensorflow/bert/TensorFlow2/bert-en-uncased-l-2-h-512-a-8/2\",\n",
    "\n",
    "    \"BERT-EN-CASED-PREPROCESSOR\"  : \"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-cased-preprocess/versions/3\",\n",
    "    \"BERT-EN-UNCASED-PREPROCESSOR\": \"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3\",\n",
    "}\n",
    "\n",
    "bert_encoder = \"BERT-EN-UNCASED-L-2-H-512-A-8\"\n",
    "preprocessor = \"BERT-EN-UNCASED-PREPROCESSOR\"\n",
    "classifier_model_1 = ClassifierModel(tfhub_map[preprocessor], tfhub_map[bert_encoder])\n",
    "classifier_model_1.compile_model(train_ds=train_ds,\n",
    "                                 validation_data=val_ds,\n",
    "                                 epochs=epochs, \n",
    "                                 learning_rate=learning_rate, \n",
    "                                 optimizer_type=optimizer_type, \n",
    "                                 loss=loss, \n",
    "                                 metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model       : https://www.kaggle.com/models/tensorflow/bert/TensorFlow2/bert-en-uncased-l-2-h-512-a-8/2\n",
      "Preprocessor: https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3\n",
      "\n",
      "epochs       : 8\n",
      "learning_rate: 1e-06\n",
      "\n",
      "Epoch 1/8\n",
      "158/158 [==============================] - 17s 83ms/step - loss: 1.4101 - accuracy: 0.2758 - val_loss: 1.3424 - val_accuracy: 0.3322\n",
      "Epoch 2/8\n",
      "158/158 [==============================] - 12s 78ms/step - loss: 1.3606 - accuracy: 0.3162 - val_loss: 1.2815 - val_accuracy: 0.4629\n",
      "Epoch 3/8\n",
      "158/158 [==============================] - 12s 78ms/step - loss: 1.3195 - accuracy: 0.3712 - val_loss: 1.2293 - val_accuracy: 0.5972\n",
      "Epoch 4/8\n",
      "158/158 [==============================] - 12s 78ms/step - loss: 1.2723 - accuracy: 0.4469 - val_loss: 1.1772 - val_accuracy: 0.6608\n",
      "Epoch 5/8\n",
      "158/158 [==============================] - 12s 78ms/step - loss: 1.2377 - accuracy: 0.5012 - val_loss: 1.1389 - val_accuracy: 0.6820\n",
      "Epoch 6/8\n",
      "158/158 [==============================] - 12s 78ms/step - loss: 1.2109 - accuracy: 0.5178 - val_loss: 1.1100 - val_accuracy: 0.6855\n",
      "Epoch 7/8\n",
      "158/158 [==============================] - 12s 78ms/step - loss: 1.1871 - accuracy: 0.5515 - val_loss: 1.0926 - val_accuracy: 0.6890\n",
      "Epoch 8/8\n",
      "158/158 [==============================] - 12s 78ms/step - loss: 1.1757 - accuracy: 0.5586 - val_loss: 1.0872 - val_accuracy: 0.6890\n",
      "\n",
      "Total training time: 103.08s\n"
     ]
    }
   ],
   "source": [
    "classifier_model_1.train()\n",
    "training_time = classifier_model_1.training_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 2s 41ms/step - loss: 1.0987 - accuracy: 0.7098\n",
      "22/22 [==============================] - 2s 100ms/step\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Algebra     0.5556    0.8333    0.6667       174\n",
      "Combinatorics     0.8641    0.5633    0.6820       158\n",
      "     Geometry     0.7906    0.9391    0.8585       197\n",
      "Number Theory     0.7714    0.4655    0.5806       174\n",
      "\n",
      "     accuracy                         0.7112       703\n",
      "    macro avg     0.7454    0.7003    0.6969       703\n",
      " weighted avg     0.7442    0.7112    0.7026       703\n",
      "\n",
      "loss: 1.098677396774292\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "report, loss, heatmap = classifier_model_1.evaluate_test(test_ds)\n",
    "accuracy, precision, recall, f1 = report['accuracy'], report['weighted avg']['precision'], report['weighted avg']['recall'], report['weighted avg']['f1-score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xx,classification,BERT-EN-UNCASED-L-2-H-512-A-8,16,8,1e-06,adamw,tf.keras.losses.sparse_categorical_crossentropy,1.098677396774292,0.7112375533428165,0.7441925649897034,0.7112375533428165,0.7025681035603188,103.0834864\n"
     ]
    }
   ],
   "source": [
    "print(f\"xx,classification,{bert_encoder},{batch_size},{epochs},{learning_rate},{optimizer_type},tf.keras.losses.sparse_categorical_crossentropy,{loss},{accuracy},{precision},{recall},{f1},{training_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier_model_1.plot_training_history_over_time(figsize=(14, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model\n",
    "# temp_path1 = \"saved_models/classification/BERT-CASED-L-12-H-768-A-12\"\n",
    "# classifier_model_1.model.save(temp_path1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss1: 0.49538768231868746\n",
      "Log Loss2: 0.4953877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow import constant\n",
    "from tensorflow import reduce_mean\n",
    "\n",
    "\n",
    "y_true = constant([0, 1, 2, 0, 1])\n",
    "\n",
    "y_pred_proba = constant([\n",
    "    [0.7, 0.2, 0.1],\n",
    "    [0.1, 0.6, 0.3],\n",
    "    [0.2, 0.3, 0.5],\n",
    "    [0.8, 0.1, 0.1],\n",
    "    [0.3, 0.5, 0.2]\n",
    "])\n",
    "\n",
    "loss1 = log_loss(y_true, y_pred_proba)\n",
    "loss2 = reduce_mean(sparse_categorical_crossentropy(y_true, y_pred_proba)).numpy()\n",
    "\n",
    "\n",
    "print(\"Log Loss1:\", loss1)\n",
    "print(\"Log Loss2:\", loss2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aops_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
